{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾Ğ¹ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚\n",
        "data = {\n",
        "    'text': [\n",
        "        \"Ñ Ñ‚Ğ°Ğº ÑÑ‡Ğ°ÑÑ‚Ğ»Ğ¸Ğ²!)))\",\n",
        "        \"Ñƒ Ğ¼ĞµĞ½Ñ Ñ…Ğ¾Ñ€Ğ¾ÑˆĞµĞµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ğµ!\",\n",
        "        \"ÑĞµĞ³Ğ¾Ğ´Ğ½Ñ Ğ½Ğµ Ğ¾Ñ‡ĞµĞ½ÑŒ Ñ…Ğ¾Ñ€Ğ¾ÑˆĞ¸Ğ¹ Ğ´ĞµĞ½ÑŒ(\",\n",
        "        \"ĞºĞ°Ğº Ğ¶Ğµ Ñ Ğ²Ğ°Ñ Ğ»ÑĞ±Ğ»Ñ!\",\n",
        "        \"Ğ¾Ğ½ Ğ¼ĞµĞ½Ñ Ğ½Ğµ ÑĞ»Ñ‹ÑˆĞ¸Ñ‚...\",\n",
        "        \"ÑÑ‚Ğ¾ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾ Ğ¿Ğ¾Ñ‚Ñ€ÑÑĞ°ÑÑ‰Ğµ!!!\",\n",
        "        \"Ñƒ Ğ¼ĞµĞ½Ñ Ğ¿Ğ»Ğ¾Ñ…Ğ¾Ğµ Ğ¿Ñ€ĞµĞ´Ñ‡ÑƒĞ²ÑÑ‚Ğ²Ğ¸Ğµ((\",\n",
        "        \"Ğ²ÑĞµ Ğ±ÑƒĞ´ĞµÑ‚ Ñ…Ğ¾Ñ€Ğ¾ÑˆĞ¾)\",\n",
        "        \"Ğ½Ğ°Ğ´Ğ¾ Ğ±Ñ‹Ğ»Ğ¾ Ğ¿Ğ¾Ğ¾ÑÑ‚Ğ¾Ñ€Ğ¾Ğ¶Ğ½ĞµĞµ...\",\n",
        "        \"Ğ¼Ğ½Ğµ Ğ³Ñ€ÑƒÑÑ‚Ğ½Ğ¾(\",\n",
        "        \"Ñ Ğ² Ğ±Ğ¾Ğ»ÑŒÑˆĞ¾Ğ¼ Ğ²Ğ¾ÑÑ‚Ğ¾Ñ€Ğ³Ğµ!!\",\n",
        "        \"Ñ‚Ñ‹ Ğ¼Ğ¾Ğ»Ğ¾Ğ´ĞµÑ†!!\",\n",
        "        \"ÑĞµĞ³Ğ¾Ğ´Ğ½Ñ Ğ±Ñ‹Ğ» ÑƒĞ¶Ğ°ÑĞ½Ñ‹Ğ¹ Ğ´ĞµĞ½ÑŒ((\",\n",
        "        \"ĞºĞ°ĞºĞ¸Ğµ Ğ²Ñ‹ ĞºÑ€ÑƒÑ‚Ñ‹Ğµ!\",\n",
        "        \"Ñ Ğ½Ğµ ÑĞ¿Ñ€Ğ°Ğ²Ğ¸Ğ»Ğ°ÑÑŒ...\",\n",
        "        \"ÑÑ‚Ğ¾ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾ Ğ½ĞµĞ²ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾!\",\n",
        "        \"Ğ¾Ñ‡ĞµĞ½ÑŒ Ğ³Ñ€ÑƒÑÑ‚Ğ½Ğ¾ ((\",\n",
        "        \"Ñƒ Ğ¼ĞµĞ½Ñ Ğ²ÑĞµ ÑÑƒĞ¿ĞµÑ€)\",\n",
        "        \"Ğ½Ğ°Ğ´Ğ¾ Ğ±Ñ‹Ğ»Ğ¾ Ğ´ÑƒĞ¼Ğ°Ñ‚ÑŒ...\",\n",
        "        \"Ñ‡ÑƒĞ²ÑÑ‚Ğ²ÑƒÑ ÑĞµĞ±Ñ Ğ½Ğµ Ğ¾Ñ‡ĞµĞ½ÑŒ(\",\n",
        "        \"Ğ¼Ğ½Ğµ Ğ¾Ñ‡ĞµĞ½ÑŒ Ğ²ĞµÑĞµĞ»Ğ¾!!\"\n",
        "\n",
        "    ],\n",
        "    'emotion': [\n",
        "        \"ÑĞ¸Ğ»ÑŒĞ½Ğ°Ñ Ñ€Ğ°Ğ´Ğ¾ÑÑ‚ÑŒ\",\n",
        "        \"Ğ²Ğ¾ÑÑ…Ğ¸Ñ‰ĞµĞ½Ğ¸Ğµ\",\n",
        "        \"Ğ³Ñ€ÑƒÑÑ‚ÑŒ\",\n",
        "        \"ÑĞ¸Ğ»ÑŒĞ½Ğ°Ñ Ñ€Ğ°Ğ´Ğ¾ÑÑ‚ÑŒ\",\n",
        "        \"Ñ€Ğ°Ğ·Ğ¾Ñ‡Ğ°Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ\",\n",
        "        \"Ğ²Ğ¾ÑÑ…Ğ¸Ñ‰ĞµĞ½Ğ¸Ğµ\",\n",
        "        \"Ğ¾Ğ³Ñ€Ğ¾Ğ¼Ğ½Ğ°Ñ Ğ³Ñ€ÑƒÑÑ‚ÑŒ\",\n",
        "        \"Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾ Ğ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹\",\n",
        "        \"Ñ€Ğ°Ğ·Ğ¾Ñ‡Ğ°Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ\",\n",
        "        \"Ğ³Ñ€ÑƒÑÑ‚ÑŒ\",\n",
        "        \"ÑĞ¸Ğ»ÑŒĞ½Ğ°Ñ Ñ€Ğ°Ğ´Ğ¾ÑÑ‚ÑŒ\",\n",
        "        \"Ğ²Ğ¾ÑÑ…Ğ¸Ñ‰ĞµĞ½Ğ¸Ğµ\",\n",
        "        \"Ğ³Ñ€ÑƒÑÑ‚ÑŒ\",\n",
        "        \"ÑĞ¸Ğ»ÑŒĞ½Ğ°Ñ Ñ€Ğ°Ğ´Ğ¾ÑÑ‚ÑŒ\",\n",
        "        \"Ñ€Ğ°Ğ·Ğ¾Ñ‡Ğ°Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ\",\n",
        "        \"Ğ²Ğ¾ÑÑ…Ğ¸Ñ‰ĞµĞ½Ğ¸Ğµ\",\n",
        "        \"Ğ¾Ğ³Ñ€Ğ¾Ğ¼Ğ½Ğ°Ñ Ğ³Ñ€ÑƒÑÑ‚ÑŒ\",\n",
        "        \"Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾ Ğ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹\",\n",
        "        \"Ñ€Ğ°Ğ·Ğ¾Ñ‡Ğ°Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ\",\n",
        "        \"Ğ³Ñ€ÑƒÑÑ‚ÑŒ\",\n",
        "        \"ÑĞ¸Ğ»ÑŒĞ½Ğ°Ñ Ñ€Ğ°Ğ´Ğ¾ÑÑ‚ÑŒ\"\n",
        "\n",
        "    ]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ° Ğ² CSV Ñ„Ğ°Ğ¹Ğ»\n",
        "df.to_csv('emotions_dataset.csv', index=False)"
      ],
      "metadata": {
        "id": "5VMG0h0A6PsN"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ñ‚Ğ¾ĞºĞµĞ½Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€Ğ° Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(emotion_labels))\n",
        "\n",
        "# ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ Ñ‚Ğ¾ĞºĞµĞ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸\n",
        "X_encoded = tokenizer(X.tolist(), padding=True, truncation=True, return_tensors='pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dp2jOT28y51E",
        "outputId": "012ce88c-4f50-4c40-bad2-0f188354f645"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "# Ğ Ğ°Ğ·Ğ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ½Ğ° Ñ‚Ñ€ĞµĞ¹Ğ½ Ğ¸ Ñ‚ĞµÑÑ‚\n",
        "X = df['text']\n",
        "y = df['emotion']\n",
        "\n",
        "# ĞŸÑ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·ÑƒĞµĞ¼ Ğ¼ĞµÑ‚ĞºĞ¸ ÑĞ¼Ğ¾Ñ†Ğ¸Ğ¹ Ğ² Ñ‡Ğ¸ÑĞ»Ğ¾Ğ²Ñ‹Ğµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ\n",
        "emotion_labels = {label: idx for idx, label in enumerate(set(y))}\n",
        "y = np.array([emotion_labels[label] for label in y])\n",
        "y = to_categorical(y)  # ĞŸÑ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·ÑƒĞµĞ¼ Ğ² one-hot encoding\n",
        "\n",
        "# Ğ’ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ‚ĞµĞºÑÑ‚Ğ°\n",
        "vectorizer = CountVectorizer()\n",
        "X_vectorized = vectorizer.fit_transform(X).toarray()\n",
        "\n",
        "# Ğ Ğ°Ğ·Ğ´ĞµĞ»ÑĞµĞ¼ Ğ½Ğ° Ğ¾Ğ±ÑƒÑ‡Ğ°ÑÑ‰ÑƒÑ Ğ¸ Ñ‚ĞµÑÑ‚Ğ¾Ğ²ÑƒÑ Ğ²Ñ‹Ğ±Ğ¾Ñ€ĞºĞ¸\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "FKGzko5LyOTw"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ½ĞµĞ¹Ñ€Ğ¾ÑĞµÑ‚Ğ¸\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(len(emotion_labels), activation='softmax'))  # Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ½Ğ¾Ğ¹ ÑĞ»Ğ¾Ğ¹ Ğ´Ğ»Ñ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸ ÑĞ¼Ğ¾Ñ†Ğ¸Ğ¹\n",
        "\n",
        "# ĞšĞ¾Ğ¼Ğ¿Ğ¸Ğ»Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# ĞĞ±ÑƒÑ‡Ğ°ĞµĞ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=5, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uz-v8-_wySRo",
        "outputId": "c09a3bdb-cc8b-4c1e-ba38-8be58559e1c2"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.1967 - loss: 1.7666 - val_accuracy: 0.0000e+00 - val_loss: 1.8754\n",
            "Epoch 2/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3200 - loss: 1.7182 - val_accuracy: 0.2000 - val_loss: 1.8715\n",
            "Epoch 3/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4167 - loss: 1.6823 - val_accuracy: 0.2000 - val_loss: 1.8667\n",
            "Epoch 4/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6117 - loss: 1.6499 - val_accuracy: 0.2000 - val_loss: 1.8633\n",
            "Epoch 5/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6500 - loss: 1.6196 - val_accuracy: 0.2000 - val_loss: 1.8600\n",
            "Epoch 6/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7467 - loss: 1.5903 - val_accuracy: 0.2000 - val_loss: 1.8562\n",
            "Epoch 7/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8433 - loss: 1.5612 - val_accuracy: 0.2000 - val_loss: 1.8525\n",
            "Epoch 8/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8433 - loss: 1.5316 - val_accuracy: 0.2000 - val_loss: 1.8481\n",
            "Epoch 9/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8433 - loss: 1.5016 - val_accuracy: 0.2000 - val_loss: 1.8417\n",
            "Epoch 10/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8433 - loss: 1.4708 - val_accuracy: 0.2000 - val_loss: 1.8357\n",
            "Epoch 11/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9017 - loss: 1.4390 - val_accuracy: 0.2000 - val_loss: 1.8276\n",
            "Epoch 12/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9017 - loss: 1.4069 - val_accuracy: 0.2000 - val_loss: 1.8182\n",
            "Epoch 13/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9017 - loss: 1.3743 - val_accuracy: 0.2000 - val_loss: 1.8091\n",
            "Epoch 14/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9017 - loss: 1.3391 - val_accuracy: 0.2000 - val_loss: 1.8000\n",
            "Epoch 15/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9017 - loss: 1.3021 - val_accuracy: 0.2000 - val_loss: 1.7918\n",
            "Epoch 16/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9017 - loss: 1.2633 - val_accuracy: 0.4000 - val_loss: 1.7827\n",
            "Epoch 17/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9017 - loss: 1.2231 - val_accuracy: 0.4000 - val_loss: 1.7714\n",
            "Epoch 18/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.1831 - val_accuracy: 0.4000 - val_loss: 1.7585\n",
            "Epoch 19/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.1421 - val_accuracy: 0.4000 - val_loss: 1.7448\n",
            "Epoch 20/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.0989 - val_accuracy: 0.4000 - val_loss: 1.7323\n",
            "Epoch 21/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.0540 - val_accuracy: 0.4000 - val_loss: 1.7193\n",
            "Epoch 22/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.0074 - val_accuracy: 0.4000 - val_loss: 1.7048\n",
            "Epoch 23/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.9600 - val_accuracy: 0.4000 - val_loss: 1.6889\n",
            "Epoch 24/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.9127 - val_accuracy: 0.4000 - val_loss: 1.6732\n",
            "Epoch 25/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.8651 - val_accuracy: 0.4000 - val_loss: 1.6568\n",
            "Epoch 26/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.8182 - val_accuracy: 0.4000 - val_loss: 1.6401\n",
            "Epoch 27/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.7712 - val_accuracy: 0.4000 - val_loss: 1.6254\n",
            "Epoch 28/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.7249 - val_accuracy: 0.4000 - val_loss: 1.6128\n",
            "Epoch 29/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.6798 - val_accuracy: 0.4000 - val_loss: 1.6005\n",
            "Epoch 30/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.6359 - val_accuracy: 0.4000 - val_loss: 1.5898\n",
            "Epoch 31/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.5931 - val_accuracy: 0.4000 - val_loss: 1.5785\n",
            "Epoch 32/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.5523 - val_accuracy: 0.4000 - val_loss: 1.5677\n",
            "Epoch 33/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.5141 - val_accuracy: 0.4000 - val_loss: 1.5570\n",
            "Epoch 34/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.4776 - val_accuracy: 0.4000 - val_loss: 1.5457\n",
            "Epoch 35/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.4432 - val_accuracy: 0.4000 - val_loss: 1.5363\n",
            "Epoch 36/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.4113 - val_accuracy: 0.4000 - val_loss: 1.5273\n",
            "Epoch 37/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.3815 - val_accuracy: 0.4000 - val_loss: 1.5190\n",
            "Epoch 38/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.3535 - val_accuracy: 0.4000 - val_loss: 1.5132\n",
            "Epoch 39/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.3273 - val_accuracy: 0.4000 - val_loss: 1.5075\n",
            "Epoch 40/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.3030 - val_accuracy: 0.4000 - val_loss: 1.5002\n",
            "Epoch 41/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.2812 - val_accuracy: 0.4000 - val_loss: 1.4939\n",
            "Epoch 42/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.2605 - val_accuracy: 0.4000 - val_loss: 1.4882\n",
            "Epoch 43/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.2414 - val_accuracy: 0.4000 - val_loss: 1.4829\n",
            "Epoch 44/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.2236 - val_accuracy: 0.4000 - val_loss: 1.4783\n",
            "Epoch 45/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.2073 - val_accuracy: 0.4000 - val_loss: 1.4741\n",
            "Epoch 46/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.1923 - val_accuracy: 0.4000 - val_loss: 1.4708\n",
            "Epoch 47/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.1787 - val_accuracy: 0.4000 - val_loss: 1.4686\n",
            "Epoch 48/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.1665 - val_accuracy: 0.4000 - val_loss: 1.4677\n",
            "Epoch 49/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.1550 - val_accuracy: 0.4000 - val_loss: 1.4652\n",
            "Epoch 50/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.1446 - val_accuracy: 0.4000 - val_loss: 1.4625\n",
            "Epoch 51/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.1352 - val_accuracy: 0.4000 - val_loss: 1.4616\n",
            "Epoch 52/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.1266 - val_accuracy: 0.4000 - val_loss: 1.4621\n",
            "Epoch 53/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.1186 - val_accuracy: 0.4000 - val_loss: 1.4624\n",
            "Epoch 54/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.1113 - val_accuracy: 0.4000 - val_loss: 1.4611\n",
            "Epoch 55/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.1046 - val_accuracy: 0.4000 - val_loss: 1.4600\n",
            "Epoch 56/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0984 - val_accuracy: 0.4000 - val_loss: 1.4598\n",
            "Epoch 57/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0926 - val_accuracy: 0.4000 - val_loss: 1.4614\n",
            "Epoch 58/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0874 - val_accuracy: 0.4000 - val_loss: 1.4617\n",
            "Epoch 59/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0825 - val_accuracy: 0.4000 - val_loss: 1.4623\n",
            "Epoch 60/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0780 - val_accuracy: 0.4000 - val_loss: 1.4638\n",
            "Epoch 61/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0738 - val_accuracy: 0.4000 - val_loss: 1.4653\n",
            "Epoch 62/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0699 - val_accuracy: 0.4000 - val_loss: 1.4652\n",
            "Epoch 63/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0664 - val_accuracy: 0.4000 - val_loss: 1.4653\n",
            "Epoch 64/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0631 - val_accuracy: 0.4000 - val_loss: 1.4663\n",
            "Epoch 65/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0601 - val_accuracy: 0.4000 - val_loss: 1.4677\n",
            "Epoch 66/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0573 - val_accuracy: 0.4000 - val_loss: 1.4682\n",
            "Epoch 67/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0546 - val_accuracy: 0.4000 - val_loss: 1.4671\n",
            "Epoch 68/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0521 - val_accuracy: 0.4000 - val_loss: 1.4659\n",
            "Epoch 69/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0498 - val_accuracy: 0.4000 - val_loss: 1.4651\n",
            "Epoch 70/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0477 - val_accuracy: 0.4000 - val_loss: 1.4640\n",
            "Epoch 71/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0456 - val_accuracy: 0.4000 - val_loss: 1.4630\n",
            "Epoch 72/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0438 - val_accuracy: 0.4000 - val_loss: 1.4626\n",
            "Epoch 73/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0420 - val_accuracy: 0.4000 - val_loss: 1.4641\n",
            "Epoch 74/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0403 - val_accuracy: 0.4000 - val_loss: 1.4659\n",
            "Epoch 75/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0387 - val_accuracy: 0.4000 - val_loss: 1.4671\n",
            "Epoch 76/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0373 - val_accuracy: 0.4000 - val_loss: 1.4683\n",
            "Epoch 77/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0359 - val_accuracy: 0.4000 - val_loss: 1.4694\n",
            "Epoch 78/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0345 - val_accuracy: 0.4000 - val_loss: 1.4696\n",
            "Epoch 79/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0333 - val_accuracy: 0.4000 - val_loss: 1.4700\n",
            "Epoch 80/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0321 - val_accuracy: 0.4000 - val_loss: 1.4701\n",
            "Epoch 81/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0310 - val_accuracy: 0.4000 - val_loss: 1.4713\n",
            "Epoch 82/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0300 - val_accuracy: 0.4000 - val_loss: 1.4720\n",
            "Epoch 83/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0289 - val_accuracy: 0.4000 - val_loss: 1.4722\n",
            "Epoch 84/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0280 - val_accuracy: 0.4000 - val_loss: 1.4727\n",
            "Epoch 85/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0271 - val_accuracy: 0.4000 - val_loss: 1.4733\n",
            "Epoch 86/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0262 - val_accuracy: 0.4000 - val_loss: 1.4737\n",
            "Epoch 87/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0254 - val_accuracy: 0.4000 - val_loss: 1.4737\n",
            "Epoch 88/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0246 - val_accuracy: 0.4000 - val_loss: 1.4739\n",
            "Epoch 89/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0239 - val_accuracy: 0.4000 - val_loss: 1.4745\n",
            "Epoch 90/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0232 - val_accuracy: 0.4000 - val_loss: 1.4756\n",
            "Epoch 91/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0225 - val_accuracy: 0.4000 - val_loss: 1.4763\n",
            "Epoch 92/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0218 - val_accuracy: 0.4000 - val_loss: 1.4766\n",
            "Epoch 93/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0212 - val_accuracy: 0.4000 - val_loss: 1.4768\n",
            "Epoch 94/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0206 - val_accuracy: 0.4000 - val_loss: 1.4770\n",
            "Epoch 95/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0200 - val_accuracy: 0.4000 - val_loss: 1.4778\n",
            "Epoch 96/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0195 - val_accuracy: 0.4000 - val_loss: 1.4790\n",
            "Epoch 97/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0189 - val_accuracy: 0.4000 - val_loss: 1.4790\n",
            "Epoch 98/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0184 - val_accuracy: 0.4000 - val_loss: 1.4799\n",
            "Epoch 99/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0179 - val_accuracy: 0.4000 - val_loss: 1.4804\n",
            "Epoch 100/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0175 - val_accuracy: 0.4000 - val_loss: 1.4809\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e95e3d17490>"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ±Ğ¸Ğ±Ğ»Ğ¸Ğ¾Ñ‚ĞµĞºĞ¸ transformers, ĞµÑĞ»Ğ¸ Ğ¾Ğ½Ğ° ĞµÑ‰Ğµ Ğ½Ğµ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ°\n",
        "!pip install transformers\n",
        "\n",
        "# Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ñ‹Ñ… ĞºĞ»Ğ°ÑÑĞ¾Ğ²\n",
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "# Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ° TrainingArguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    logging_dir='./logs',\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtFrSwan0dIJ",
        "outputId": "f3c12342-16b7-476b-c23c-716ebe5b14ea"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ĞÑ†ĞµĞ½ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'ĞŸĞ¾Ñ‚ĞµÑ€Ğ¸: {loss}, Ğ¢Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUO18-q-yXnA",
        "outputId": "0d854c46-6106-421d-dd64-c2facbec6ec8"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4000 - loss: 1.4809\n",
            "ĞŸĞ¾Ñ‚ĞµÑ€Ğ¸: 1.4809434413909912, Ğ¢Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ: 0.4000000059604645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_emotion(text):\n",
        "    vectorized_text = vectorizer.transform([text]).toarray()\n",
        "    prediction = model.predict(vectorized_text)\n",
        "    predicted_emotion = np.argmax(prediction)\n",
        "    return list(emotion_labels.keys())[predicted_emotion]\n",
        "\n",
        "# ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ\n",
        "print(predict_emotion(\"Ğ³Ñ€ÑƒÑÑ‚Ğ½Ğ¾(\"))  # ĞŸÑ€Ğ¾Ğ³Ğ½Ğ¾Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ ÑĞ¼Ğ¾Ñ†Ğ¸Ñ"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYpXMIoGybuw",
        "outputId": "5598d8d2-4544-4342-cebd-16830106a8c8"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Ğ¾Ğ³Ñ€Ğ¾Ğ¼Ğ½Ğ°Ñ Ğ³Ñ€ÑƒÑÑ‚ÑŒ\n"
          ]
        }
      ]
    }
  ]
}